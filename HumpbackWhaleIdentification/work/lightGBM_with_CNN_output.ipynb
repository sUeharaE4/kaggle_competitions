{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "0c43062b45b2f97a3da6314f8d26da365cfc06bc"
   },
   "source": [
    "# Machine Learning approach\n",
    "Siamese Network outputs 512 dims vector. This competition data set is unbalance so try over sampling without image augmentation I chose SMOTE.  \n",
    "At first get siamese outputs from train dataset with train some epochs. Then train lightGBM and predict by siamese outputs from test dataset.\n",
    "## BE CAREFUL!\n",
    "This approach is not work. May be the gap between train dataset outputs and test dataset outputs is big... So my lightGBM model predict const values.  \n",
    "This note is just for how to use lightGBM (and tuning with optuna), PCA and SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: optuna in /opt/conda/lib/python3.6/site-packages (0.7.0)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from optuna) (1.16.0)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from optuna) (1.12.0)\n",
      "Requirement already satisfied: typing in /opt/conda/lib/python3.6/site-packages (from optuna) (3.6.4)\n",
      "Requirement already satisfied: cliff in /opt/conda/lib/python3.6/site-packages (from optuna) (2.14.0)\n",
      "Requirement already satisfied: sqlalchemy>=1.1.0 in /opt/conda/lib/python3.6/site-packages (from optuna) (1.2.7)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.6/site-packages (from optuna) (0.23.4)\n",
      "Requirement already satisfied: colorlog in /opt/conda/lib/python3.6/site-packages (from optuna) (4.0.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from optuna) (1.1.0)\n",
      "Requirement already satisfied: pyparsing>=2.1.0 in /opt/conda/lib/python3.6/site-packages (from cliff->optuna) (2.2.0)\n",
      "Requirement already satisfied: stevedore>=1.20.0 in /opt/conda/lib/python3.6/site-packages (from cliff->optuna) (1.30.0)\n",
      "Requirement already satisfied: cmd2!=0.8.3; python_version >= \"3.0\" in /opt/conda/lib/python3.6/site-packages (from cliff->optuna) (0.9.7)\n",
      "Requirement already satisfied: PyYAML>=3.12 in /opt/conda/lib/python3.6/site-packages (from cliff->optuna) (3.12)\n",
      "Requirement already satisfied: PrettyTable<0.8,>=0.7.2 in /opt/conda/lib/python3.6/site-packages (from cliff->optuna) (0.7.2)\n",
      "Requirement already satisfied: pbr!=2.1.0,>=2.0.0 in /opt/conda/lib/python3.6/site-packages (from cliff->optuna) (5.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/lib/python3.6/site-packages (from pandas->optuna) (2.6.0)\n",
      "Requirement already satisfied: pytz>=2011k in /opt/conda/lib/python3.6/site-packages (from pandas->optuna) (2018.4)\n",
      "Requirement already satisfied: attrs>=16.3.0 in /opt/conda/lib/python3.6/site-packages (from cmd2!=0.8.3; python_version >= \"3.0\"->cliff->optuna) (18.1.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.7 in /opt/conda/lib/python3.6/site-packages (from cmd2!=0.8.3; python_version >= \"3.0\"->cliff->optuna) (0.1.7)\n",
      "Requirement already satisfied: pyperclip>=1.5.27 in /opt/conda/lib/python3.6/site-packages (from cmd2!=0.8.3; python_version >= \"3.0\"->cliff->optuna) (1.7.0)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.6/site-packages (from cmd2!=0.8.3; python_version >= \"3.0\"->cliff->optuna) (0.3.9)\n",
      "Requirement already satisfied: lightgbm in /opt/conda/lib/python3.6/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.6/site-packages (from lightgbm) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.6/site-packages (from lightgbm) (0.20.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.6/site-packages (from lightgbm) (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install optuna\n",
    "!pip install lightgbm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_uuid": "2cfb9fd091be7ab2ffb16878225b987dff31d230"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "humpback-whale-identification  p2h-tmp\tscore-and-etc\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from os.path import isfile\n",
    "\n",
    "import lightgbm as lgb\n",
    "import matplotlib.pyplot as plt #Visulization\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import scipy.stats\n",
    "\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "\n",
    "import matplotlib\n",
    "% matplotlib inline\n",
    "plt.style.use('ggplot') \n",
    "# font = {'family' : 'meiryo'}\n",
    "# matplotlib.rc('font', **font)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "73e8f32748d5164ef5904c0546551935b80f1e15"
   },
   "source": [
    "# Load Data and Normalization\n",
    "These dump file is (fknown, fsubmit, h2i, train, h2ws, known) from trained results of https://www.kaggle.com/seesee/siamese-pretrained-0-822  \n",
    "fknown : CNN output of known(train) images  \n",
    "fsubmit : CNN output of unknown(test) images  \n",
    "  \n",
    "Although lightGBM doesn't need normalize data, this kernel create features from some CNN outputs. So normalize may be need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_uuid": "1bdadf813e6543755965d260874bcaa00ad91f55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_dump1\n",
      "load_dump2\n",
      "load_dump3\n",
      "load_dump4\n",
      "load p2h\n"
     ]
    }
   ],
   "source": [
    "TRAIN_DF = '../input/humpback-whale-identification/train.csv'\n",
    "SUB_Df = '../input/humpback-whale-identification/sample_submission.csv'\n",
    "TRAIN = '../input/humpback-whale-identification/train/'\n",
    "TEST = '../input/humpback-whale-identification/test/'\n",
    "P2H = '../input/p2h-tmp/p2h_.pickle'\n",
    "P2SIZE = '../input/metadata/p2size.pickle'\n",
    "BB_DF = \"../input/metadata/bounding_boxes.csv\"\n",
    "\n",
    "tagged = dict([(p, w) for _, p, w in pd.read_csv(TRAIN_DF).to_records()])\n",
    "submit = [p for _, p, _ in pd.read_csv(SUB_Df).to_records()]\n",
    "join = list(tagged.keys()) + submit\n",
    "\n",
    "dump_path1 = '../input/score-and-etc/standard_250_002_joblib_without_score'\n",
    "dump_path2 = '../input/score-and-etc/standard_500_010_joblib_without_score'\n",
    "dump_path3 = '../input/score-and-etc/standard_550_009_joblib_without_score'\n",
    "dump_path4 = '../input/score-and-etc/standard_600_002_joblib_without_score'\n",
    "\n",
    "def get_normalized_ndarray(ndarray):\n",
    "    ndarray_norm = scipy.stats.zscore(ndarray, axis=None)\n",
    "    ndarray_norm = ndarray_norm / ndarray_norm.max().max()\n",
    "    return ndarray_norm\n",
    "\n",
    "if isfile(dump_path1):\n",
    "    fknown1, fsubmit1, h2i, train, h2ws, known = joblib.load(dump_path1)\n",
    "    print('load_dump1')\n",
    "\n",
    "if isfile(dump_path2):\n",
    "    fknown2, fsubmit2, h2i, train, h2ws, known = joblib.load(dump_path2)\n",
    "    print('load_dump2')\n",
    "\n",
    "if isfile(dump_path3):\n",
    "    fknown3, fsubmit3, h2i, train, h2ws, known = joblib.load(dump_path3)\n",
    "    print('load_dump3')\n",
    "    \n",
    "if isfile(dump_path4):\n",
    "    fknown4, fsubmit4, h2i, train, h2ws, known = joblib.load(dump_path4)\n",
    "    print('load_dump4')\n",
    "\n",
    "if isfile(P2H):\n",
    "    with open(P2H, 'rb') as f:\n",
    "        p2h = pickle.load(f)\n",
    "        print('load p2h')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "_uuid": "b034678e24493448e97fbcf798ac18be9de9e99d"
   },
   "outputs": [],
   "source": [
    "fknown1 = get_normalized_ndarray(fknown1)\n",
    "fknown2 = get_normalized_ndarray(fknown2)\n",
    "fknown3 = get_normalized_ndarray(fknown3)\n",
    "fknown4 = get_normalized_ndarray(fknown4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_uuid": "a17f1277dd8c33ae346dd2e87d32ff923dcafd87"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25360/25360 [00:43<00:00, 580.87it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_keys_from_value(d, val):\n",
    "    return [k for k, v in d.items() if v == val]\n",
    "known_list = [get_keys_from_value(p2h, known_id)[0] for known_id in tqdm(known)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_uuid": "a53070760f5cc6de142a36ff5bb8b1b852789768"
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_DF)\n",
    "train_df_has_id = train_df[train_df['Id'] != 'new_whale']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "a5a2b79b7e0b0420dc393989ca57fd67c67b93d6"
   },
   "source": [
    "# PCA to down dims\n",
    "512 dim is too high dims! It's not memory friendly. So, show PCA results and decide how many features I use.  \n",
    "In this sample, top 60 features can explane almost 80%, so I use 60 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_uuid": "73a4f343d91509f95c365602d2f7ae7f7b8185b1"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from scipy import stats\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# k_cluster_num = 15\n",
    "# # K-meansによるクラスタリング\n",
    "# kmeans_model = KMeans(n_clusters=k_cluster_num).fit(new_whales)\n",
    "\n",
    "# # PCAで次元削減\n",
    "# pca = PCA(n_components=2)\n",
    "# new_whales_pca = pca.fit_transform(new_whales)\n",
    "# print('end clustering')\n",
    "# cmap = plt.get_cmap(\"tab10\")\n",
    "# # 結果を散布図にプロット\n",
    "# plt.figure()\n",
    "# for (i, label) in enumerate(tqdm(kmeans_model.labels_)):\n",
    "#     plt.scatter(new_whales_pca[i, 0], new_whales_pca[i, 1], c=cmap(label))\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_uuid": "d4f544e480ebbf19a6291f061f12fb1652801d24"
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "pca_n_components = 512\n",
    "pca_all = PCA(n_components=pca_n_components)\n",
    "X_train_pca_all = pca_all.fit_transform(fknown1)\n",
    "# pca_all.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "_uuid": "0993e6b6b152b5647d0d73815f69cd644510b9bf"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(1, pca_n_components+1), pca_all.explained_variance_ratio_, alpha=0.5, align='center')\n",
    "plt.step(range(1, pca_n_components+1), np.cumsum(pca_all.explained_variance_ratio_), where='mid')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "383126458b8f444f0044ee12726a47551df5ec2d"
   },
   "source": [
    "This plot means PCA's top 60 features can explane 80% of original features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_uuid": "3af0a61c71ca8c2e70dbb1b05b44c50640e4a5b8"
   },
   "outputs": [],
   "source": [
    "del pca_all\n",
    "\n",
    "pca_n_components = 60\n",
    "pca = PCA(n_components=pca_n_components)\n",
    "X_train_pca = pca.fit_transform(fknown1)\n",
    "# pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_uuid": "ef2d8c1131de2a8e0ff06e3296dbd5507463efb3",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAENCAYAAAAVPvJNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAIABJREFUeJzt3XuYXFWd7vFvSMfBcBFiKdpJkKBBzSCKMkEdxCtzgjqAR/0ZGDlcxByVCIp3x0FA8SCOCEpUYogiiuGFcTQzBsErjB7kCeJ4joERQwTSgGIIFyGAufT8sXaTSlHdvapTl11V7+d5+um9V63ae610p369LnutScPDw5iZmdXaodMFMDOzcnKAMDOzuhwgzMysLgcIMzOrywHCzMzqcoAwM7O6HCDMzKwuBwgzM6vLAcLMzOoa6HQBtpMfAzczm5hJ42Xo9gDBnXfemZ23Uqmwbt26FpamfVyXcnJdysl12dbg4GBWPncxmZlZXQ4QZmZWlwOEmZnV5QBhZmZ1tW2QOiLmAecBk4Elks6qeX1P4CJgtyLPhyWtaFf5zMxsW21pQUTEZGARcCgwBzgyIubUZPsYIEn7A/OBL7ajbGZmVl+7upjmAqslrZH0F2AZcHhNnmFg1+L4SUD+/FUzM2u6dnUxTQfWVp0PAQfW5DkNuCoi3g3sBLymPUUzM7N6yvSg3JHA1yR9NiJeAlwcEftK2lKdKSIWAAsAJFGpVLJvMDAw0FD+MnNdysl1KaduqcuGq77DI9f8YMw8Dz7z2VSOO6kt5WlXgLgDmFl1PqNIq/Y2YB6ApGsjYkegAtxdnUnSYmBxcTrcyBOFfpqynFyXcnJdWmvLNd9n+Lprtk28+Tfp+z77jvq+KVu2tO1J6nYFiJXA7IiYRQoM84GjavLcDrwa+FpEPBfYEfhTm8pnZtYy2cFgn32ZdODB7HDwvFGvtUulwqNtCnZtCRCSNkXEQuBK0hTWpZJWRcQZwPWSlgPvA74SEe8lDVgfK8mL8ZlZV2lmMOi0ScPDXf0ZPOzF+rqf61JOrsu26n7w1zNKN1GzgkETF+vr/dVczcyaadRAkDE+MPJ62VsGuRwgzKxvNTRQ3EMf/LkcIMysL/TS2EC7OECYWc+pDQbrp0xheNWv0omDQTYHCDPram4ZtI4DhJl1jYkGg2k9NCOrnRwgzKyU3DLoPAcIM+s4B4NycoAws7ZyMOgeDhBm1jIOBt3NAcLMWmb4umtg7e9h5qytiQ4GXcMBwsyaom5roQgOkz/wqc4UyraLA4SZNaShtYpmzmLSgQe3p2DWdA4QZjYqr1XU3xwgzAzw8hT2eA4QZgZ4QNkezwHCrA/lDCh7eQprW4CIiHnAeaQtR5dIOqvm9c8BryxOpwJPlbRbu8pn1quyxxE8oGw12hIgImIysAg4BBgCVkbEckk3juSR9N6q/O8G9m9H2cx6nbuObKLa1YKYC6yWtAYgIpYBhwM3jpL/SODjbSqbWc/wswjWTO0KENOBtVXnQ8CB9TJGxDOAWcCP21Aus67lriNrtTIOUs8HLpe0ud6LEbEAWAAgiUqlkn3hgYGBhvKXmetSTu2sy/obrmXT0K0MzJq9NfGv92fHgw9h6t8dsd3X98+lnNpZl4YCRETsAOwB/FHSlgbeegcws+p8RpFWz3zgxNEuJGkxsLg4HW5klkWlh2ZluC7l1Kq6jNV1tOU9p2+TvAHY0IQy+OdSTs2oy+DgYFa+rAAREbuQBpnnF+/ZWIwjnCTp/oxLrARmR8QsUmCYDxxV5z7PAXYHrs0qvVkPcteRlUVuC+ILwE7AvsBtwDOAM4HPA8eM92ZJmyJiIXAlaZrrUkmrIuIM4HpJy4us84FlkoYbq4ZZ7/CsIyuL3AAxD9hb0obi/OaIOA64JfdGklYAK2rSTq05Py33ema9wLOOrMx2yMz3CPCUmrQK8Ghzi2PWXx5rLVRz15GVRG4LYgnwg4g4h61dTO9l62CxmY3DrQXrNrkB4kzgTtLA8mBxfDawtEXlMus5dccW3FqwEssKEMWg8VIcEMzGNeqGOm4tWJcZNUBExNGSLi6Ojx8tnyQHDbMqdVsK4NaCdZ2xWhBHAhcXx0ePkmekZWHWl+ptsuOWgvWKUQOEpNdWHb9ytHxm/czjCtbLcp+k/pWkxy2/HRHXSzqg+cUyKx9vsmP9Jvc5iGfVJkTEJGDv5hbHrLz8zIL1mzFbEBHx9eLwCVXHI/YCVrWiUGad5mcWzMbvYrpllONh4OfAZU0vkVkJeGzBbJwAIel0gIj4haQr21Mks/Zya8GsvtwH5a6MiCcAzyatwTSp6jXv/GZdza0Fs/pyZzEdROpO+itgV+ABYBfSNqIeqLau4daCWb7cWUyfA86WNA34c/H9E8AXW1YysxbwTCSzfLmL9e0DnFeTdhbwe+Cfm1oisyZxa8Fs++S2IO4ndS0B3BURc0hbg+7cklKZNYFbC2bbJ7cF8W3gtcAlpLWXfgJsBC7PvVFEzCO1QiYDSySdVSdPAKeRptH+WtLj9q02a4hbC2YTljuL6T1Vx/8cEb8gDVJnTX2NiMnAIuAQYAhYGRHLJd1YlWc28BHgbyXdGxFPza+G9buxupPMbGLGDRDFh/vNwBxJjwJI+lmD95kLrJa0prjmMuBw4MaqPG8HFkm6t7jH3Q3ew/qYp6qaNd+4AULS5ojYDOzIxPegnk6aEjtiCDiwJs8+ABHxc1I31GmSvj/B+1kP8+CzWXvkjkGcCygiPkX6cB8eeWGkVdCksswGXgHMAK6JiOdJuq86U0QsABYU96ZSqeTfYGCgofxl1s91WX/DtWwaupWBWbO3Ju69DzsefAhTO/xv0s8/lzJzXSZ4r8x85xffD6lJHyb9tT+eO4CZVeczirRqQ8B1kjYCv4+Im0kBY2V1JkmLgcUj929kaeVKDy3F3M912bxxI8zYiy3vOX2b9A3Ahg7/m/Tzz6XMXJdtDQ4OZuXLHaTOnQ47mpXA7IiYRQoM84HaGUrfIe1i99WIqJC6nJrVOrEu5cFns87Z3g/+LJI2AQtJs55uSklaFRFnRMRhRbYrgXsi4kbSNNoPSLqnHeWz8vKzDGadM2l4eHj8XOU1fOedd2ZndjOznMaqy+bPfBSgawaf++Xn0m1cl20VXUyTxsuXOwZh1nLuTjIrl7Z0MZnlcHeSWblktyAiYgrwYmBQ0qURsROApIdaVTjrQ36Wwaw0cveDeB6wnPSg3AzgUuDlwDHAW1pWOutJtV1J66dMSVNX3Z1kViq5XUxfAk6V9BzSIn0AVwMHtaRU1tPqdiWBu5PMSia3i+mvgW8Ux8OQupYi4oktKZX1vqqupGk9NMPErJfkBohbgRcB148kRMRcYHULymQ9xDOTzLpXbhfTPwHfi4jTgSdExEdIe1R/rGUls57gmUlm3St3qY1/Lzb8eTtp7OEZwP+U9MtWFs56hGcmmXWl7Gmukn4FvKuFZbEu5+4ks96S1cUUEd+OiJfVpL0sIrK3HLXe5+4ks96S24J4OfDmmrRrSSuwmm3l7iSznpEbIB4BdgIeqErbma3PRFifcXeSWe/LncV0JXBBROwKUHw/H/CWoH3K3UlmvS+3BfE+0oNy6yNiPTANuAI4ulUFsy7g7iSznpY7zfVe4HUR8TTS1qFrJf2hpSWz0nB3kll/anS57y3APcDUiNg7IvZuQZmsZNydZNafcldznQdcCDy95qVhYHID1zivyL9E0lk1rx8LfIa0ZzXA+ZKW5Fzb2sDdSWZ9J3cMYhHwCeAiSQ83epOImFxc4xBgCFgZEcsl3ViT9VJJCxu9vpmZNV9ugNgduEDSRDewnguslrQGICKWAYcDtQHCOszjDWY2IncM4kLguO24z3RgbdX5UJFW640R8f8i4vKImLkd97MJ8niDmY3IbUG8GDgpIj4MbDN7SVKzPjn+DfiWpEcj4n8DFwGvqs0UEQuABcW9qVQq2TcYGBhoKH+Ztaou66dMgb33YdonFzX92qPxz6WcXJdyamddcgPEkuJrou4gTY8dMYOtg9EASLqn5n5n17uQpMXA4uJ0uJGNZio9tDFNq+qyeWN6OL6d/07+uZST61JOzajL4OBgVr7c5yAu2q7SwEpgdkTMIgWG+cBR1Rki4umS7ipODwNu2s572jg83mBmY8le7jsi9iANNleASSPpkpaO915JmyJiIWnJjsnAUkmrIuIM4HpJy0ldWIcBm4D1wLGNVMQa99h4Q3VA8HiDmRVyn4M4grTUxu9I+1OvAvYFfgaMGyAAJK0AVtSknVp1/BHgI1mltubx8w1mNorcWUyfBI6TtD/wUPF9AeAd5czMelRuF9Oeki6rSbuINKPp/c0tkrWCxxvMrFG5LYi7izEIgFsj4iXAM8lcZsM6z883mFmjclsQXwEOAv4F+BzwE9LCfZ9tUbmsFTzeYGYNyJ3m+umq469HxE+BnSR5KqqZWY/KnuZaTdLtzS6INY/HG8ysGUYNEBFxk6TnFsdrSUt7P46kPVtUNpsgP99gZs0wVgvi7VXHb211QazJPN5gZttp1AAh6Wfw2F4OxwMLJD3aroKZmVlnjTvNVdJm4O9Is5bMzKxP5A5Sfw44PSI+LmljKwtkjfGAtJm1Sm6AeDfwNOCUiPgTVQPWHqTuLA9Im1mr5AYID1KXmQekzawFch+Uu7rVBTEzs3JpZD+IFwAv4/H7QZw66pvMzKxr5e4HsYA0UH0VcChwBWlm03dbVzSrVT0gvX7KlLQ9qAekzaxFcldz/SAwT9IbgIeL728CPKOpjbwiq5m1U24X01Ml/UdxvCUidpB0RUR8M/dGETEPOI+0RPgSSWeNku+NwOXA30i6Pvf6faMYkJ7WQ5uwm1k55bYghiJir+L4ZuDwiHgZ8JecNxdPYy8idU/NAY6MiDl18u0CnAxcl1kuMzNrkdwAcTbw3OL4DNL+1D8GTs98/1xgtaQ1kv4CLAMOr5PvE8CngUcyr2tmZi2SFSAkfU3SFcXxFcDuwO6SvpR5n+nA2qrzoSLtMRHxQmCmpO9lXtPMzFoodxbTucA3Ja0EKFoBWd1LmdffATgHODYj7wJgQVEOKpVK9n0GBgYayt9JG676Do9c84Nt0rYM3crArNlMq1S6qi7jcV3KyXUpp3bWJXeQehLw3Yh4CLgEuETSbxu4zx3AzKrzGUXaiF2AfYGfRgSkZT2WR8RhtQPVkhYDi4vT4UYGaitdNLC7+UcrHj+FdcZebHrhS1i3bl1X1WU8rks5uS7l1Iy6DA4OZuXLfZL65Ih4L/Bq4EjgFxGxhtSqOCfjEiuB2RExixQY5gNHVV3/ftIDeAAUW5q+v+9nMXkJDTProNxBaiRtkfQDSceT/tq/B/hM5ns3AQuBK4GbUpJWRcQZEXHYBMptZmYt1shSGzsBbyC1IF4BXA0ck/t+SSuAFTVpdZfpkPSK3OuamVlr5A5SX0Z6huEG4FvAMZJ6o0PPzMzqym1BrATeJ+n2VhamH9Xd8Ae8xpKZdVzuIPXZrS5Iv6q74Q94jSUz67jsMQhrIc9WMrMSyp7FZGZm/cUBwszM6hq1i6lY/mJckrY0rzhmZlYWY41BbAKGM64xuUllMTOzEhkrQFRPq3kdaQe5/wPcBjwD+BDwL60rWu+pO6XV01nNrKRGDRCSbhs5johTgAMk3Vck3RwR1wPXA7lLfve9ulNaPZ3VzEoqd5rrk4CpwH1VaVOLdGuEp7SaWZfIDRAXAT8s9oVYS1q6+6Qi3czMelBugPggsBp4CzAI3AWcD3ylReUyM7MOy11qYwvw5eLLzMz6QO5qrpOAE0gb/TxF0n4RcTDwNElqZQHNzKwzcp+kPgN4G6lLac8ibYg01dXMzHpQ7hjEscD+ktZFxMi01t8De7ekVD3AzzyYWbfLDRCTgQeL45Gnq3euShtXRMwDziuutUTSWTWvvwM4EdhcXHeBpBtzr182fubBzLpdboBYAZwTEe+Fx8YkPgH8W86bI2IysAg4hNQ1tTIiltcEgEskfbnIfxhwDjAvs3zl5GcezKyL5Y5BnAI8Hbif9HDcg2xdbiPHXGC1pDWS/gIsAw6vziDpgarTnchbB8rMzFokd5rrA8AbIuKppMCwVtIfGrjPdNIDdiOGgANrM0XEiaRg9ATgVQ1c38zMmmwiO8rdA0yNiL0BJK1pVmEkLQIWRcRRwMeAY2rzRMQCYEGRn0qlkn39gYGBhvJvj/VTpgAwrUX3a2ddWs11KSfXpZzaWZfc5yDmAReSupmqDZO33PcdpOU5Rswo0kazjFEWAZS0GFg8cv9169Zl3D6pVCo0kn97bN64EaBl92tnXVrNdSkn16WcmlGXwcHBrHy5LYhFpEHpiyQ9PIHyrARmR8QsUmCYDxxVnSEiZkv6XXH6OuB3mJlZx+QGiN2BCyRNaOBY0qaIWAhcSWpxLJW0KiLOAK6XtBxYGBGvATYC91Kne8nMzNonN0BcCBwHLJ3ojSStIE2XrU47ter45Ileu9P8UJyZ9aLcAPFi4KSI+DCwzewlSX3/5JcfijOzXpQbIJYUXzYaPxRnZj0m9zkIbwxkZtZnRg0QEXG0pIuL4+NHyydpwuMSZmZWXmO1II4ELi6Ojx4lzzDbMXBtZmblNWqAkPTaquNXtqc4ZmZWFg0vtVGs5Dpp5LzYjtTMzHpM7lIb04HzgYOB3Wpezllqw8zMukxuC+LLwAbg1cDVpEBxGjUPvvUDPxRnZv0idz+IlwLHS/pPYFjSr0l7VL+vZSUrqcceiqvmh+LMrAfltiA2A5uK4/si4inAA6R9HvqPH4ozsz6Q24K4DhiZ1XQlcCnwbeD6VhTKzMw6L7cFcTRbg8l7gPcDOwPntqJQZmbWeblLbdxXdfwwaW8IMzPrYWMttXFGzgWql+w2M7PeMVYLYuYYr5mZWY8ba6mN49pZEDMzK5fspTYiYjYQwCBwJ6CqPaRz3j8POI/05PUSSWfVvH4KcAJpOu2fSM9d3JZ7fTMza66saa4RcRTwK2A/4CHgecANRXrO+ycDi4BDgTnAkRExpybbr4ADJO0HXA6cnVUDMzNridwWxCeB10p6bI2JiHgZaTnwSzLePxdYLWlN8d5lwOHAjSMZJP2kKv8vgLdmlq1lvKyGmfWz3AfldgGurUn7BbBT5vunA2urzocY+ynstwFXZF67Zbyshpn1s9wWxDnApyLinyQ9EhFPBE4v0psqIt4KHAC8fJTXFwALACRRqVSyrz0wMNBQ/vVTpsDe+zDtk4uy39MujdalzFyXcnJdyqmddckNEO8CngacHBH3AruT9oS4KyLeOZJJ0p6jvP8Otp02O6NI20ZEvAb4R+Dlkh6tdyFJi4HFxenwunXrMqsAlUqFRvJv3rgRoKH3tEujdSkz16WcXJdyakZdBgcHs/LlBojtHQ9YCcyOiFmkwDAf2GaAOyL2By4A5km6ezvvZ2Zm2yl3qY2r66VHxBRJGzPevykiFpIW+psMLJW0qnha+3pJy4HPkNZ3uiwiAG6XdFhmPczMrMlyd5T7AfC/JN1VlbYfaRbT83OuIWkFNRsMVS/TIek1OdcxM7P2yO1iugH4ddEKuAz4EPBB4KOtKpiZmXVW1jRXSR8C3gh8Gvg9cBgwV9KXW1g2MzProNznIABmAbuSlsHYCdixJSUyM7NSyF1q43JSd9I8SX9DmmZ6TUR8oJWFMzOzzskdg7gb2L/YLAhJi4qB64tJs4+6npfVMDPbVu4YxLtGgkNV2s3AS1tSqg7wshpmZtsaswUREZ+XdFLV+dskXViVRaTB694wcxaTP/CpTpfCzKwUxmtBHFtzXtuddEjzimJmZmUyXoCYNM65mZn1qPECxPA452Zm1qPGm8U0EBGvZGvLofZ8cstKZmZmHTVegLgbWFp1fk/NuVddNTPrUWMGCEl7takcZmZWMo0stWFmZn3EAcLMzOpygDAzs7ocIMzMrK7cxfq2W0TMA84jTY1dIumsmtcPBs4F9gPmS7q8XWUzM7PHa0sLIiImA4uAQ4E5wJERMacm2+2kpT0uaUeZzMxsbO1qQcwFVktaAxARy4DDgRtHMki6tXhtS5vKxJZlX2F4ZAVXL+1tZraNdgWI6cDaqvMh4MA23buuLcsvYXjNb+GBe1OCl/Y2M9tG28YgmiUiFgALACRRqVSy3zswMPBY/genToW5Bz322s7zT2huQVusui7dznUpJ9elnNpZl3YFiDuAmVXnM4q0hklaTNryFGB43bp12e+tVCqM5N+yYcM2rz3SwHXKoLou3c51KSfXpZyaUZfBwcGsfO0KECuB2RExixQY5gNHteneZmY2AW2ZxSRpE7AQuBK4KSVpVUScERGHAUTE30TEEPBm4IKIWNWOspmZWX1tG4OQtAJYUZN2atXxSlLXk5mZlYCfpDYzs7ocIMzMrC4HCDMzq8sBwszM6nKAMDOzuhwgzMysrq5baqOVtizfdiHZHQ7zs3xm1r/cgjAzs7ocIMzMrC53MY2jttsJ3PVkZv3BAWKCPF5hZr3OXUxmZlaXWxBNVK9V4ZaGmXUrB4gOcCAxs27gLiYzM6vLLYgSG6ul8eDUqWzZsMEtDTNrGQeIHpDbZeVuLDNrRNsCRETMA84DJgNLJJ1V8/pfAV8HXgTcA7xF0q3tKl+/Gu05DwcdM2tLgIiIycAi4BBgCFgZEcsl3ViV7W3AvZKeFRHzgU8Db2lH+ay5Gg0u1d1l2xOYctJG0s1sfO1qQcwFVktaAxARy4DDgeoAcThwWnF8OXB+REySNNymMlofaVUgamewGysAtqMu1vvaFSCmA2urzoeAA0fLI2lTRNwPPBlY15YSmllDOhEARwJTtwXuZgb9dk5QmTQ83Po/0CPiTcA8SScU50cDB0paWJXnN0WeoeL8liLPupprLQAWAEh6UcsLb2bWmyaNl6Fdz0HcAcysOp9RpNXNExEDwJNIg9XbkLRY0gGSDiBVMPsrIn7Z6HvK+uW6lPPLdSnnl+tS92tc7epiWgnMjohZpEAwH6htHy0HjgGuBd4E/NjjD2ZmndOWFoSkTcBC4ErgppSkVRFxRkQcVmS7EHhyRKwGTgE+3I6ymZlZfW17DkLSCmBFTdqpVcePAG9ucTEWt/j67eS6lJPrUk6uywS0ZZDazMy6jxfrMzOzuvpmLabxlvoos4hYCrweuFvSvkXaNOBSYC/gViAk3dupMuaIiJmk5VT2AIaBxZLO69K67AhcA/wV6f/R5ZI+XkzEWEZ6hueXwNGS/tK5kuYrVjy4HrhD0uu7tS4RcSvwZ2AzsEnSAd34OwYQEbsBS4B9Sf9njgd+S5vq0hctiKqlPg4F5gBHRsSczpaqIV8D5tWkfRj4kaTZwI/ojkH9TcD7JM0BXgycWPwcurEujwKvkvR84AXAvIh4MWmJmM9JehZwL2kJmW5xMmkSyYhurssrJb2gmA4P3fk7BumP2u9Leg7wfNLPp2116YsAQdVSH8VfQCNLfXQFSdcA62uSDwcuKo4vAo5oa6EmQNJdkm4ojv9M+mWfTnfWZVjSg8XplOJrGHgVaakY6JK6AETEDOB1pL9WiYhJdGldRtF1v2MR8STgYNIMTyT9RdJ9tLEu/dLFlLPUR7fZQ9JdxfEfSN02XSMi9gL2B66jS+tStEx/CTyL1EK9BbivmNYN6fdseoeK16hzgQ8CuxTnT6Z76zIMXBURw8AFkhbTnb9js4A/AV+NiOeTftdOpo116ZcWRE8rHijsmuloEbEz8C/AeyQ9UP1aN9VF0mZJLyCtDDAXeE6HizQhETEyvvXLTpelSQ6S9EJSl/KJEXFw9Ytd9Ds2ALwQ+JKk/YGHqOlOanVd+iVA5Cz10W3+GBFPByi+393h8mSJiCmk4PBNSd8ukruyLiOKZv9PgJcAuxVLxUD3/J79LXBYMbi7jNS1dB7dWRck3VF8vxv4V1Lw7sbfsSFgSNJ1xfnlpIDRtrr0S4B4bKmPiHgCaamP5R0u0/YaWZqE4vt3O1iWLEW/9oXATZLOqXqpG+vylGKGCRHxRNJeJzeRAsWbimxdURdJH5E0Q9JepP8bP5b0D3RhXSJip4jYZeQY+DvgN3Th75ikPwBrI+LZRdKrSVsktK0uffOgXES8ltTPOhlYKunMDhcpW0R8C3gFUAH+CHwc+A4gYE/gNtJUt9qB7FKJiIOA/wD+P7ClSP4oaRyi2+qyH2mAcDLpDy1JOiMi9ib9FT4N+BXwVkmPdq6kjYmIVwDvL6a5dl1dijL/a3E6AFwi6cyIeDJd9jsGEBEvIE0ceAKwBjiO4veNNtSlbwKEmZk1pl+6mMzMrEEOEGZmVpcDhJmZ1eUAYWZmdTlAmJlZXQ4QVhoRcUVEHDN+zjGv8bKI+G2TyvPTiDihGdcy60b9shaTdUDxZO4epGWXHwKuABZWLXK3DUmHbu89Jf0H8OxxM9qERcRpwLMkvbXTZbHWcgvCWu3vJe1MWiLgAOBjtRkiYlJE+HfRrGTcgrC2kHRHRFxB2viEiPgp8HPSE+IvBJ4XEUuAb0haEhHHAicAvyDtQ3Af8C5JVxTvnwZ8FvgfwBOBqyUdUTwJ/A1JM4p8twIXAEcDTyc9gf5OSY9ExO7AxaSVfQeK8rxD0tB49SlWcv1QUbanAjcDR0haGxEvJa1ltE+RfrKk/1tV75+R1jvaj7ScxbHA54G/J20G82ZJtxb5h0kreL4H2BX4KvAhSVuKoPpR4O3Fv8H3gXdLur9YLff3xbU/AUwl7e1wZnHdHUirt74d2I20r8A7JK0f673FxlsfBSZFxBHALZKeX/y8TgWeAqwDPibpm+P9O1q5+a82a4tiN7nXkpZsGHE0sIC0xPRtdd52IOkDswKcDVxYrOcE6YN9KvDXpA/oz41x+38gBZJnkj60R1oxO5A+cJ9BWrbgYeD8zCqdAhxZ1GlX0k5fG4rA9T3SB/6TgXOA7xVLPYyYT6r79KJM1xblmEZaz+njNfd6A6n19ULSXgDHF+nHFl+vBPYGdq5T/oNIXW6vBk6NiOcW6e8m7SPwcmCQtCHQovHeK+n7wKeASyXtXASHnYr6HippF+ClwH+O/k9n3cItCGu170TEJuB+0gfnp6pe+5qkVSMnEVG1SPRAAAAC/klEQVT73tskfaV47SLgi8AeRZA4FHhy1VaLV49RhvMlrS2ucybwBdJfuPeQVpal6rWfZNbrBOCDkkYGxH9dXONo4HeSLi7SvxURJ5FaB18r0r4q6ZYi/xXAHEk/LM4vI/3VXu3TxVo76yPiXFJgWkIKfOdIWlO89yPAbyLiuKr3ni7pYeDXEfFrtu5K9g7SeNBQ8d7TgNuL8o/33nq2APtGxO3FXgV3jZLPuogDhLXaESMffnWsHSV9xB9GDiRtKALIzqS/tNc3sA9v9X1uI/3FTERMJbU85gG7F6/vEhGTJW0e55ozSRsE1Rrk8a2h29h2s50/Vh0/XOd855zy17nXbaT/09UbyPyh6nhD1bWfAfxrRGypen1z5nu3IemhiHgL8H5SK+/npK1l/6tefuse7mKyTproSpFrgWkjy21nqN4LZE/gzuL4faQulAMl7Ura3hFgEuNbS+oeqnUn6cO32p5s314Ko5W/9l57kvb9rg44o1lL6hLareprx5G9FMbxuJ+bpCslHUIa5/kv4CsZ17GScwvCuo6ku4qumS9GxInAg8BLir276zkxIv6d9FfwPwKXFum7kP5iv68YO6jt+x/LEuATEXEjsBp4HikIrAC+EBFHkZZkfiMwB/j3RupY4wMRcR3pL/iTSeMaAN8CPlT8W/yJrWMDm+p019X6MnBmRBwj6baIeArwUkk5ewv8ETgkInYoBsv3AF4M/JD07/kgW5dzty7mFoR1q6OBjaS/Vu8mzfIZzSXAVaT19G8BPlmkn0ua/bOONFvq+w3c/xxSALgKeIC0EdITi3GN15NaJ/eQZgq9XtK6Bq5d67uk/Yj/kzSOc2GRvpQ0WH8NadbRI6TB5xznkTaeuSoi/kyqf+4+7ZcV3++JiBtInyOnkFo060kD3+/MvJaVmPeDsJ5WTHM9YYxxkFIrprnOlrS602Wx/uMWhJmZ1eUAYWZmdbmLyczM6nILwszM6nKAMDOzuhwgzMysLgcIMzOrywHCzMzqcoAwM7O6/htiOEqkp7j5rAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.bar(range(1, pca_n_components+1), pca.explained_variance_ratio_, alpha=0.5, align='center')\n",
    "plt.step(range(1, pca_n_components+1), np.cumsum(pca.explained_variance_ratio_), where='mid')\n",
    "plt.ylabel('Explained variance ratio')\n",
    "plt.xlabel('Principal components')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "_uuid": "c31900ce891efdc072c22fe5bb44dd808757d709"
   },
   "outputs": [],
   "source": [
    "def get_trained_df(train_df, pca, fknown):\n",
    "#     trained_df = trained_df.reset_index(drop=True)\n",
    "    known_df = pd.DataFrame(pca.fit_transform(fknown))\n",
    "    known_df['Id'] = train_df['Id']\n",
    "    known_df['Image'] = train_df['Image']\n",
    "    return known_df\n",
    "\n",
    "cols = ['col' + str(i+1) for i in range(pca_n_components)]\n",
    "cols.append('Id')\n",
    "cols.append('Image')\n",
    "\n",
    "known_df1 = get_trained_df(train_df, pca, fknown1)\n",
    "known_df2 = get_trained_df(train_df, pca, fknown2)\n",
    "known_df3 = get_trained_df(train_df, pca, fknown3)\n",
    "known_df4 = get_trained_df(train_df, pca, fknown4)\n",
    "\n",
    "known_df1.columns = cols\n",
    "known_df2.columns = cols\n",
    "known_df3.columns = cols\n",
    "known_df4.columns = cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "_uuid": "c92c1132f7341de17497bcfd891d4f3ec1330004"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25360, 62)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_df1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "_uuid": "c6ab231a9db7ebd51a5bf30cc5a93016d94d68ed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col1</th>\n",
       "      <th>col2</th>\n",
       "      <th>col3</th>\n",
       "      <th>col4</th>\n",
       "      <th>col5</th>\n",
       "      <th>col6</th>\n",
       "      <th>col7</th>\n",
       "      <th>col8</th>\n",
       "      <th>col9</th>\n",
       "      <th>col10</th>\n",
       "      <th>col11</th>\n",
       "      <th>col12</th>\n",
       "      <th>col13</th>\n",
       "      <th>col14</th>\n",
       "      <th>col15</th>\n",
       "      <th>col16</th>\n",
       "      <th>col17</th>\n",
       "      <th>col18</th>\n",
       "      <th>col19</th>\n",
       "      <th>col20</th>\n",
       "      <th>col21</th>\n",
       "      <th>col22</th>\n",
       "      <th>col23</th>\n",
       "      <th>col24</th>\n",
       "      <th>col25</th>\n",
       "      <th>col26</th>\n",
       "      <th>col27</th>\n",
       "      <th>col28</th>\n",
       "      <th>col29</th>\n",
       "      <th>col30</th>\n",
       "      <th>col31</th>\n",
       "      <th>col32</th>\n",
       "      <th>col33</th>\n",
       "      <th>col34</th>\n",
       "      <th>col35</th>\n",
       "      <th>col36</th>\n",
       "      <th>col37</th>\n",
       "      <th>col38</th>\n",
       "      <th>col39</th>\n",
       "      <th>col40</th>\n",
       "      <th>col41</th>\n",
       "      <th>col42</th>\n",
       "      <th>col43</th>\n",
       "      <th>col44</th>\n",
       "      <th>col45</th>\n",
       "      <th>col46</th>\n",
       "      <th>col47</th>\n",
       "      <th>col48</th>\n",
       "      <th>col49</th>\n",
       "      <th>col50</th>\n",
       "      <th>col51</th>\n",
       "      <th>col52</th>\n",
       "      <th>col53</th>\n",
       "      <th>col54</th>\n",
       "      <th>col55</th>\n",
       "      <th>col56</th>\n",
       "      <th>col57</th>\n",
       "      <th>col58</th>\n",
       "      <th>col59</th>\n",
       "      <th>col60</th>\n",
       "      <th>Id</th>\n",
       "      <th>Image</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.264178</td>\n",
       "      <td>0.048690</td>\n",
       "      <td>-0.537960</td>\n",
       "      <td>0.499906</td>\n",
       "      <td>0.146193</td>\n",
       "      <td>0.407463</td>\n",
       "      <td>0.350210</td>\n",
       "      <td>0.832533</td>\n",
       "      <td>0.052055</td>\n",
       "      <td>-0.205541</td>\n",
       "      <td>0.106128</td>\n",
       "      <td>-0.115668</td>\n",
       "      <td>0.208277</td>\n",
       "      <td>-0.051209</td>\n",
       "      <td>-0.223187</td>\n",
       "      <td>-0.301753</td>\n",
       "      <td>0.211880</td>\n",
       "      <td>0.144791</td>\n",
       "      <td>0.089760</td>\n",
       "      <td>0.119773</td>\n",
       "      <td>0.242235</td>\n",
       "      <td>-0.140746</td>\n",
       "      <td>0.467165</td>\n",
       "      <td>0.124518</td>\n",
       "      <td>-0.042470</td>\n",
       "      <td>-0.130203</td>\n",
       "      <td>-0.026881</td>\n",
       "      <td>0.020031</td>\n",
       "      <td>0.015454</td>\n",
       "      <td>-0.067904</td>\n",
       "      <td>-0.023868</td>\n",
       "      <td>-0.007752</td>\n",
       "      <td>-0.195040</td>\n",
       "      <td>0.026055</td>\n",
       "      <td>-0.254896</td>\n",
       "      <td>0.160157</td>\n",
       "      <td>-0.041942</td>\n",
       "      <td>-0.021629</td>\n",
       "      <td>0.404598</td>\n",
       "      <td>-0.158446</td>\n",
       "      <td>-0.069839</td>\n",
       "      <td>-0.210409</td>\n",
       "      <td>0.103527</td>\n",
       "      <td>-0.193161</td>\n",
       "      <td>0.009214</td>\n",
       "      <td>-0.115216</td>\n",
       "      <td>0.186752</td>\n",
       "      <td>0.067645</td>\n",
       "      <td>0.227502</td>\n",
       "      <td>-0.177140</td>\n",
       "      <td>-0.055795</td>\n",
       "      <td>0.159767</td>\n",
       "      <td>-0.293430</td>\n",
       "      <td>-0.036427</td>\n",
       "      <td>-0.060890</td>\n",
       "      <td>-0.036987</td>\n",
       "      <td>-0.020375</td>\n",
       "      <td>0.118647</td>\n",
       "      <td>-0.044561</td>\n",
       "      <td>-0.142058</td>\n",
       "      <td>w_f48451c</td>\n",
       "      <td>0000e88ab.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.199571</td>\n",
       "      <td>-1.426987</td>\n",
       "      <td>0.169723</td>\n",
       "      <td>0.114124</td>\n",
       "      <td>-0.412073</td>\n",
       "      <td>0.094038</td>\n",
       "      <td>0.674823</td>\n",
       "      <td>0.017209</td>\n",
       "      <td>-0.092959</td>\n",
       "      <td>0.372340</td>\n",
       "      <td>-0.359052</td>\n",
       "      <td>0.566933</td>\n",
       "      <td>-0.251478</td>\n",
       "      <td>-0.205532</td>\n",
       "      <td>0.119637</td>\n",
       "      <td>-0.213704</td>\n",
       "      <td>0.160937</td>\n",
       "      <td>-0.011838</td>\n",
       "      <td>0.165289</td>\n",
       "      <td>0.179390</td>\n",
       "      <td>-0.169734</td>\n",
       "      <td>-0.187179</td>\n",
       "      <td>-0.110939</td>\n",
       "      <td>-0.134558</td>\n",
       "      <td>-0.076154</td>\n",
       "      <td>0.247997</td>\n",
       "      <td>0.202589</td>\n",
       "      <td>-0.266521</td>\n",
       "      <td>-0.065171</td>\n",
       "      <td>-0.231541</td>\n",
       "      <td>-0.098736</td>\n",
       "      <td>0.217819</td>\n",
       "      <td>-0.123969</td>\n",
       "      <td>0.299738</td>\n",
       "      <td>-0.234580</td>\n",
       "      <td>0.234897</td>\n",
       "      <td>-0.045794</td>\n",
       "      <td>-0.116894</td>\n",
       "      <td>-0.088675</td>\n",
       "      <td>0.014938</td>\n",
       "      <td>-0.117577</td>\n",
       "      <td>-0.162917</td>\n",
       "      <td>0.014832</td>\n",
       "      <td>0.190027</td>\n",
       "      <td>0.305283</td>\n",
       "      <td>0.027758</td>\n",
       "      <td>0.061812</td>\n",
       "      <td>0.186423</td>\n",
       "      <td>-0.183979</td>\n",
       "      <td>-0.192116</td>\n",
       "      <td>-0.026875</td>\n",
       "      <td>-0.055224</td>\n",
       "      <td>0.104182</td>\n",
       "      <td>-0.056677</td>\n",
       "      <td>-0.074762</td>\n",
       "      <td>-0.118298</td>\n",
       "      <td>-0.235894</td>\n",
       "      <td>-0.103579</td>\n",
       "      <td>-0.150372</td>\n",
       "      <td>0.066925</td>\n",
       "      <td>w_c3d896a</td>\n",
       "      <td>0001f9222.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.038216</td>\n",
       "      <td>-0.246276</td>\n",
       "      <td>-0.919789</td>\n",
       "      <td>0.463684</td>\n",
       "      <td>0.288893</td>\n",
       "      <td>-0.123772</td>\n",
       "      <td>0.464163</td>\n",
       "      <td>0.329865</td>\n",
       "      <td>-0.170784</td>\n",
       "      <td>-0.093173</td>\n",
       "      <td>-0.128435</td>\n",
       "      <td>-0.226512</td>\n",
       "      <td>0.325614</td>\n",
       "      <td>-0.339695</td>\n",
       "      <td>-0.085936</td>\n",
       "      <td>-0.242328</td>\n",
       "      <td>0.075520</td>\n",
       "      <td>-0.531590</td>\n",
       "      <td>0.372295</td>\n",
       "      <td>-0.373182</td>\n",
       "      <td>0.134166</td>\n",
       "      <td>0.039174</td>\n",
       "      <td>0.210661</td>\n",
       "      <td>0.070794</td>\n",
       "      <td>-0.248601</td>\n",
       "      <td>0.227369</td>\n",
       "      <td>0.142004</td>\n",
       "      <td>0.368952</td>\n",
       "      <td>-0.013981</td>\n",
       "      <td>0.044457</td>\n",
       "      <td>-0.027122</td>\n",
       "      <td>-0.181148</td>\n",
       "      <td>0.070619</td>\n",
       "      <td>0.039393</td>\n",
       "      <td>-0.372338</td>\n",
       "      <td>-0.389216</td>\n",
       "      <td>0.066688</td>\n",
       "      <td>0.033829</td>\n",
       "      <td>0.233834</td>\n",
       "      <td>-0.042382</td>\n",
       "      <td>-0.246687</td>\n",
       "      <td>0.166488</td>\n",
       "      <td>0.077790</td>\n",
       "      <td>0.142102</td>\n",
       "      <td>-0.206330</td>\n",
       "      <td>-0.002309</td>\n",
       "      <td>-0.036567</td>\n",
       "      <td>0.093173</td>\n",
       "      <td>0.195259</td>\n",
       "      <td>0.235964</td>\n",
       "      <td>-0.116430</td>\n",
       "      <td>0.099615</td>\n",
       "      <td>0.007231</td>\n",
       "      <td>0.122758</td>\n",
       "      <td>-0.006374</td>\n",
       "      <td>-0.170457</td>\n",
       "      <td>0.060859</td>\n",
       "      <td>0.080432</td>\n",
       "      <td>-0.102063</td>\n",
       "      <td>0.031347</td>\n",
       "      <td>w_20df2c5</td>\n",
       "      <td>00029d126.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.314156</td>\n",
       "      <td>-1.070764</td>\n",
       "      <td>0.632649</td>\n",
       "      <td>-0.340697</td>\n",
       "      <td>-0.114739</td>\n",
       "      <td>0.096455</td>\n",
       "      <td>-0.066383</td>\n",
       "      <td>0.634566</td>\n",
       "      <td>-0.266554</td>\n",
       "      <td>0.045849</td>\n",
       "      <td>0.569306</td>\n",
       "      <td>0.124261</td>\n",
       "      <td>0.195613</td>\n",
       "      <td>0.145980</td>\n",
       "      <td>0.089345</td>\n",
       "      <td>-0.484671</td>\n",
       "      <td>-0.016475</td>\n",
       "      <td>0.188178</td>\n",
       "      <td>0.260305</td>\n",
       "      <td>0.033706</td>\n",
       "      <td>0.068497</td>\n",
       "      <td>0.275799</td>\n",
       "      <td>-0.378565</td>\n",
       "      <td>0.009879</td>\n",
       "      <td>0.381855</td>\n",
       "      <td>0.575454</td>\n",
       "      <td>0.292861</td>\n",
       "      <td>-0.334074</td>\n",
       "      <td>-0.103937</td>\n",
       "      <td>-0.064454</td>\n",
       "      <td>0.250320</td>\n",
       "      <td>-0.174823</td>\n",
       "      <td>0.207649</td>\n",
       "      <td>0.159285</td>\n",
       "      <td>-0.096062</td>\n",
       "      <td>-0.133909</td>\n",
       "      <td>0.121387</td>\n",
       "      <td>0.012790</td>\n",
       "      <td>0.334936</td>\n",
       "      <td>-0.165551</td>\n",
       "      <td>-0.164112</td>\n",
       "      <td>0.346852</td>\n",
       "      <td>0.034763</td>\n",
       "      <td>-0.120890</td>\n",
       "      <td>-0.211293</td>\n",
       "      <td>0.177443</td>\n",
       "      <td>0.046560</td>\n",
       "      <td>-0.199754</td>\n",
       "      <td>0.068231</td>\n",
       "      <td>0.027681</td>\n",
       "      <td>0.145851</td>\n",
       "      <td>0.039909</td>\n",
       "      <td>0.045929</td>\n",
       "      <td>-0.233385</td>\n",
       "      <td>0.053391</td>\n",
       "      <td>0.191005</td>\n",
       "      <td>0.145547</td>\n",
       "      <td>-0.031886</td>\n",
       "      <td>0.086489</td>\n",
       "      <td>0.009891</td>\n",
       "      <td>new_whale</td>\n",
       "      <td>00050a15a.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.108835</td>\n",
       "      <td>-0.720869</td>\n",
       "      <td>-0.439259</td>\n",
       "      <td>0.838695</td>\n",
       "      <td>0.007478</td>\n",
       "      <td>0.098606</td>\n",
       "      <td>-0.025203</td>\n",
       "      <td>0.405101</td>\n",
       "      <td>-0.135748</td>\n",
       "      <td>0.217109</td>\n",
       "      <td>0.531329</td>\n",
       "      <td>0.424830</td>\n",
       "      <td>-0.005903</td>\n",
       "      <td>-0.514669</td>\n",
       "      <td>0.245234</td>\n",
       "      <td>-0.049665</td>\n",
       "      <td>-0.223965</td>\n",
       "      <td>-0.205195</td>\n",
       "      <td>0.064255</td>\n",
       "      <td>-0.049121</td>\n",
       "      <td>0.017264</td>\n",
       "      <td>0.162331</td>\n",
       "      <td>-0.045662</td>\n",
       "      <td>0.274439</td>\n",
       "      <td>0.086460</td>\n",
       "      <td>0.366472</td>\n",
       "      <td>0.333124</td>\n",
       "      <td>-0.313546</td>\n",
       "      <td>-0.003285</td>\n",
       "      <td>-0.022936</td>\n",
       "      <td>0.077142</td>\n",
       "      <td>0.083864</td>\n",
       "      <td>-0.168837</td>\n",
       "      <td>0.096011</td>\n",
       "      <td>-0.098746</td>\n",
       "      <td>0.031785</td>\n",
       "      <td>0.113177</td>\n",
       "      <td>-0.127011</td>\n",
       "      <td>0.052931</td>\n",
       "      <td>-0.052589</td>\n",
       "      <td>0.126258</td>\n",
       "      <td>-0.126998</td>\n",
       "      <td>-0.077997</td>\n",
       "      <td>-0.073441</td>\n",
       "      <td>0.072170</td>\n",
       "      <td>0.078832</td>\n",
       "      <td>0.017080</td>\n",
       "      <td>0.280986</td>\n",
       "      <td>-0.045867</td>\n",
       "      <td>-0.008316</td>\n",
       "      <td>0.155653</td>\n",
       "      <td>0.047897</td>\n",
       "      <td>-0.050714</td>\n",
       "      <td>-0.010041</td>\n",
       "      <td>0.098251</td>\n",
       "      <td>-0.181078</td>\n",
       "      <td>0.003836</td>\n",
       "      <td>-0.041023</td>\n",
       "      <td>-0.334156</td>\n",
       "      <td>-0.071102</td>\n",
       "      <td>new_whale</td>\n",
       "      <td>0005c1ef8.jpg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       col1      col2      ...               Id          Image\n",
       "0  0.264178  0.048690      ...        w_f48451c  0000e88ab.jpg\n",
       "1 -0.199571 -1.426987      ...        w_c3d896a  0001f9222.jpg\n",
       "2  1.038216 -0.246276      ...        w_20df2c5  00029d126.jpg\n",
       "3  0.314156 -1.070764      ...        new_whale  00050a15a.jpg\n",
       "4  0.108835 -0.720869      ...        new_whale  0005c1ef8.jpg\n",
       "\n",
       "[5 rows x 62 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "23eb7d149286292b98ffe78eaf728e4cd7299156"
   },
   "source": [
    "# UnderSampling and OverSampling\n",
    "The next cell checks each id has how many images. We know this data set is unblance data. I think balanced data give us more good result. So drop data which class has too much images and create data which data has only a little images. You can use SMOTE from imblearn library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "_uuid": "4d1945c62da83031dd9804486c66a26fa1185b0b"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>new_whale</td>\n",
       "      <td>9664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>w_23a388d</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>w_9b5109b</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>w_9c506f6</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>w_0369a5c</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id  count\n",
       "0  new_whale   9664\n",
       "1  w_23a388d     73\n",
       "2  w_9b5109b     65\n",
       "3  w_9c506f6     62\n",
       "4  w_0369a5c     61"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# id_df = pd.DataFrame(train_df[train_df['Id'] != 'new_whale']['Id'].value_counts())\n",
    "id_df = pd.DataFrame(train_df['Id'].value_counts())\n",
    "id_df = id_df.reset_index()\n",
    "id_df.columns = ['Id', 'count']\n",
    "id_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_uuid": "c96a33a5b1a20eca2845aaa4d4427c66eecf05b0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 228/228 [00:03<00:00, 66.65it/s]\n"
     ]
    }
   ],
   "source": [
    "class_cnt = 10\n",
    "known_df1_down = pd.DataFrame(columns=cols)\n",
    "known_df2_down = pd.DataFrame(columns=cols)\n",
    "known_df3_down = pd.DataFrame(columns=cols)\n",
    "known_df4_down = pd.DataFrame(columns=cols)\n",
    "\n",
    "for class_id in tqdm(id_df[id_df['count'] > class_cnt]['Id'].tolist()):\n",
    "    known_df1_down = pd.concat([known_df1_down, known_df1[known_df1['Id'] == class_id].sample(class_cnt, random_state=84*1)])\n",
    "    known_df2_down = pd.concat([known_df2_down, known_df2[known_df2['Id'] == class_id].sample(class_cnt, random_state=84*2)])\n",
    "    known_df3_down = pd.concat([known_df3_down, known_df3[known_df3['Id'] == class_id].sample(class_cnt, random_state=84*3)])\n",
    "    known_df4_down = pd.concat([known_df4_down, known_df4[known_df4['Id'] == class_id].sample(class_cnt, random_state=84*4)])\n",
    "    \n",
    "known_df1_down = pd.concat([known_df1_down, known_df1[known_df1['Id'].isin(id_df[id_df['count'] <= class_cnt]['Id'].tolist())]]).reset_index(drop=True)\n",
    "known_df2_down = pd.concat([known_df2_down, known_df2[known_df2['Id'].isin(id_df[id_df['count'] <= class_cnt]['Id'].tolist())]]).reset_index(drop=True)\n",
    "known_df3_down = pd.concat([known_df3_down, known_df3[known_df3['Id'].isin(id_df[id_df['count'] <= class_cnt]['Id'].tolist())]]).reset_index(drop=True)\n",
    "known_df4_down = pd.concat([known_df4_down, known_df4[known_df4['Id'].isin(id_df[id_df['count'] <= class_cnt]['Id'].tolist())]]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "_uuid": "cca6532f98bc2f0311bc2690c4e9dfb89919b5a5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13623, 62)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "known_df1_down.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "_uuid": "4a269a11ef79cec174b1cdf745ed420c4a3d12ab"
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "df = pd.concat([known_df1_down, known_df2_down, known_df3_down, known_df4_down]).reset_index(drop=True)\n",
    "X_train = df.drop(['Id', 'Image'], axis=1).values\n",
    "X_train = scipy.stats.zscore(X_train, axis=None)\n",
    "\n",
    "# profession = df['Id'].values\n",
    "# profession_enc = preprocessing.LabelEncoder().fit_transform(profession).reshape(-1,1)\n",
    "# y_train = OneHotEncoder().fit_transform(profession_enc).toarray()\n",
    "# print(profession_enc[:15])\n",
    "# print(y_train[:15].shape)\n",
    "y_train = df['Id'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_uuid": "5ffd1671bc1f42df1fdb5ed8439dd566da6c8b93"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 26s, sys: 51.3 s, total: 2min 17s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from imblearn.over_sampling import SMOTE\n",
    "sm = SMOTE(random_state=84, k_neighbors=1)\n",
    "X_res, y_res = sm.fit_sample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "_uuid": "e31f87980c29acc9db30b16aac73576d46cf5f70"
   },
   "outputs": [],
   "source": [
    "def shuffle_samples(X, y):\n",
    "    zipped = list(zip(X, y))\n",
    "    np.random.shuffle(zipped)\n",
    "    X_result, y_result = zip(*zipped)\n",
    "    return np.asarray(X_result), np.asarray(y_result)\n",
    "\n",
    "X_res, y_res = shuffle_samples(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "_uuid": "2ac4ce773973f1101d6989df44849c5fc49f9bcb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200200, 60)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "_uuid": "bbb6c96a5e5d0615ede4824d895d501b0fc520d5"
   },
   "outputs": [],
   "source": [
    "encoder = preprocessing.LabelEncoder()\n",
    "y_res = encoder.fit_transform(y_res).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "_uuid": "1caf08bf1bc9dbb2e58eb7870666386c56d6c268"
   },
   "outputs": [],
   "source": [
    "y_res = [label[0] for label in y_res]\n",
    "y_res = np.array(y_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "711a0474815822cc7fa047b27ba5a7149ef0e748"
   },
   "source": [
    "By the way, this kernel has a lot of val and they use memory a lot! (I know this code is dirty but when I write this code I don't have enough time)  \n",
    "So let's drop needless vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "_uuid": "0d4e7f8f0feb89a83af7005799b08749f50086fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            Variable Name|    Memory|\n",
      " ------------------------------------ \n",
      "|                    X_res|  48048112|\n",
      "|                  X_train|  13078192|\n",
      "|                       df|  22668776|\n",
      "|                  fknown1|  51937392|\n",
      "|                  fknown2|  51937392|\n",
      "|                  fknown3|  51937392|\n",
      "|                  fknown4|  51937392|\n",
      "|                 fsubmit1|  16302192|\n",
      "|                 fsubmit2|  16302192|\n",
      "|                 fsubmit3|  16302192|\n",
      "|                 fsubmit4|  16302192|\n",
      "|                      h2i|   1310816|\n",
      "|                     h2ws|   1310816|\n",
      "|                    id_df|    570674|\n",
      "|                     join|    266632|\n",
      "|                    known|    225112|\n",
      "|                known_df1|  10549864|\n",
      "|           known_df1_down|   5667272|\n",
      "|                known_df2|  10549864|\n",
      "|           known_df2_down|   5667272|\n",
      "|                known_df3|  10549864|\n",
      "|           known_df3_down|   5667272|\n",
      "|                known_df4|  10549864|\n",
      "|           known_df4_down|   5667272|\n",
      "|               known_list|    225408|\n",
      "|                      p2h|   1310816|\n",
      "|                   submit|     69160|\n",
      "|                   tagged|   1310816|\n",
      "|                    train|    198112|\n",
      "|                 train_df|   4463640|\n",
      "|          train_df_has_id|   2888272|\n",
      "|                    y_res|   1601696|\n",
      "|                  y_train|    436000|\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n",
    "print(\" ------------------------------------ \")\n",
    "for var_name in dir():\n",
    "    if not var_name.startswith(\"_\") and sys.getsizeof(eval(var_name)) > 10000: #ここだけアレンジ\n",
    "        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_uuid": "899540b7da49b5b12a82666ed32d0dfb05f63941"
   },
   "outputs": [],
   "source": [
    "del known_df1_down, known_df2_down, known_df3_down, known_df4_down\n",
    "del known_df1, known_df2, known_df3, known_df4\n",
    "del X_train_pca_all, X_train_pca, X_train, y_train, plt\n",
    "del fknown1, fknown2, fknown3, fknown4, fsubmit1, fsubmit2, fsubmit3, fsubmit4\n",
    "del df, train_df, train_df_has_id\n",
    "del h2i, h2ws, join, known, p2h, submit, tagged, train, known_list, id_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "_uuid": "00e0d09fb8a7845e4d6f6f7b446ea848e90212fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|            Variable Name|    Memory|\n",
      " ------------------------------------ \n",
      "|                    X_res|  48048112|\n",
      "|                    y_res|   1601696|\n"
     ]
    }
   ],
   "source": [
    "print(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\n",
    "print(\" ------------------------------------ \")\n",
    "for var_name in dir():\n",
    "    if not var_name.startswith(\"_\") and sys.getsizeof(eval(var_name)) > 10000: #ここだけアレンジ\n",
    "        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_uuid": "ed5e4cb4c789fde294d85d19dca0a7f5d9f00bc8"
   },
   "source": [
    "## Param tuning\n",
    "The next cell written the way of tuning lightGBM with Optuna. If you want to tune up hyper-params, please remove #s (not all just first one).  \n",
    "But it takes a lot of time so may you can't exec all trial on kernel... "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "_uuid": "1e85ddb9cf85b6cb55ac1b7724650303135ae314",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import lightgbm as lgb\n",
    "import optuna, os, uuid, pickle\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "# def train_optuna(X, y):\n",
    "#     start_time = time.time()\n",
    "#     X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10, random_state=84)\n",
    "\n",
    "#     def objectives(trial):\n",
    "#         # 試行にUUIDを設定\n",
    "#         trial_uuid = str(uuid.uuid4())\n",
    "#         trial.set_user_attr(\"uuid\", trial_uuid)\n",
    "\n",
    "#         params = {\n",
    "#             'boosting_type': trial.suggest_categorical('boosting', ['gbdt', 'dart', 'goss']),\n",
    "#             'objective': 'multiclass',\n",
    "#             'num_class': 5005,\n",
    "#             'metric': {'multi_logloss', 'multi_error'},#, 'auc'},\n",
    "#             'num_leaves': trial.suggest_int(\"num_leaves\", 10, 68),\n",
    "#             'learning_rate': trial.suggest_loguniform(\"learning_rate\", 6e-4, 9e-3),\n",
    "# #             'feature_fraction': trial.suggest_uniform(\"feature_fraction\", 0.0, 1.0),\n",
    "#             'feature_fraction': trial.suggest_uniform(\"feature_fraction\", 0.3, 0.7),\n",
    "\n",
    "#             #'device' : 'gpu',\n",
    "#             'verbose' : 0\n",
    "#         }\n",
    "#         if params['boosting_type'] == 'dart':\n",
    "#             params['drop_rate'] = trial.suggest_loguniform('drop_rate', 1e-8, 1.0)\n",
    "#             params['skip_drop'] = trial.suggest_loguniform('skip_drop', 1e-8, 1.0)\n",
    "#         if params['boosting_type'] == 'goss':\n",
    "#             params['top_rate'] = trial.suggest_uniform('top_rate', 0.0, 1.0)\n",
    "#             params['other_rate'] = trial.suggest_uniform('other_rate', 0.0, 1.0 - params['top_rate'])\n",
    "\n",
    "#         print('uuid is : ' + str(trial_uuid))\n",
    "#         print('param is ...')\n",
    "#         print(params)\n",
    "#         # 枝刈りありの訓練\n",
    "#         pruning_callback = optuna.integration.LightGBMPruningCallback(trial, \"multi_logloss\")\n",
    "#         gbm = lgb.train(params, lgb.Dataset(X_train, y_train), num_boost_round=15,\n",
    "#                         valid_sets=lgb.Dataset(X_test, y_test), callbacks=[pruning_callback],\n",
    "#                         early_stopping_rounds=5, )#categorical_feature=['size_info'])\n",
    "\n",
    "#         # 訓練、テスト誤差\n",
    "#         y_pred_train = np.rint(gbm.predict(X_train))\n",
    "#         y_pred_test = np.rint(gbm.predict(X_test))\n",
    "#         error_train = 1.0 - accuracy_score(y_train, y_pred_train)\n",
    "#         error_test = 1.0 - accuracy_score(y_test, y_pred_test)\n",
    "\n",
    "#         # エラー率の記録\n",
    "#         trial.set_user_attr(\"train_error\", error_train)\n",
    "#         trial.set_user_attr(\"test_error\", error_test)\n",
    "\n",
    "#         # モデルの保存\n",
    "#         if not os.path.exists(\"lgb_output\"):\n",
    "#             os.mkdir(\"lgb_output\")\n",
    "#         with open(\"lgb_output/\"+f\"{trial_uuid}.pkl\", \"wb\") as fp:\n",
    "#             pickle.dump(gbm, fp)\n",
    "\n",
    "# #         process_time = time.time() - start_time\n",
    "# #         print(str(process_time - start_time))\n",
    "# #         print('*********************************************************************')\n",
    "# #         print(trial_uuid)\n",
    "# #         print('error_train : ' + str(error_train))\n",
    "# #         print('error_test : ' + str(error_test))\n",
    "# #         print('*********************************************************************')\n",
    "#         return error_test\n",
    "\n",
    "#     study = optuna.create_study()\n",
    "#     # SQLiteに記録する場合は、ディスクアクセスが遅いとボトルネックになることもある\n",
    "#     #study = optuna.create_study(storage=\"sqlite:///brestcancer_lgb.db\", study_name=\"brestcancer_lgb\")\n",
    "#     study.optimize(objectives, n_trials=500)\n",
    "\n",
    "# #     print(study.best_params)\n",
    "# #     print(study.best_value)\n",
    "\n",
    "#     # best_paramsにはuser_attrは表示されないのでtrialから呼ぶ（dict形式で記録されている）\n",
    "#     print(study.best_trial.user_attrs)\n",
    "\n",
    "#     df = study.trials_dataframe()\n",
    "#     output_csv = 'optuna_lgb.csv'\n",
    "# #     df.to_csv(output_csv)\n",
    "# #     shutil.copyfile(output_csv, '/content/drive/My Drive/share/kaggle/competition/HumpbackWhaleIdentification/result/' + output_csv)\n",
    "    \n",
    "#     return study.best_trial.user_attrs\n",
    "    \n",
    "# result_dict = train_optuna(X_res, y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "_uuid": "e8603b4349cb1967db8f016818d5fc3f58ac649a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's multi_error: 0.377722\n",
      "Training until validation scores don't improve for 5 rounds.\n",
      "[2]\tvalid_0's multi_error: 0.313886\n",
      "[3]\tvalid_0's multi_error: 0.28047\n",
      "[4]\tvalid_0's multi_error: 0.258891\n",
      "[5]\tvalid_0's multi_error: 0.244905\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[5]\tvalid_0's multi_error: 0.244905\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_res, y_res, test_size=0.10, random_state=84)\n",
    "del X_res, y_res\n",
    "\n",
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'multiclass',\n",
    "    'num_class': 5005,\n",
    "    'metric': ['multi_error'],\n",
    "    'num_leaves': 45,\n",
    "    'learning_rate': 0.002097358935704443,\n",
    "    'feature_fraction': 0.6696988478476772,\n",
    "    'verbose' : 0\n",
    "}\n",
    "\n",
    "gbm = lgb.train(params, lgb.Dataset(X_train, y_train), num_boost_round=5,\n",
    "                        valid_sets=lgb.Dataset(X_test, y_test),# callbacks=['maluti_error'],\n",
    "                        early_stopping_rounds=5, \n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "_uuid": "62f79b0724b69bb6867f1998c3c512d44b4833a9"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gbm_joblib']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del X_train, X_test, y_train, y_test\n",
    "dump_data = (gbm, params)\n",
    "joblib.dump(dump_data, 'gbm_joblib', compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "_uuid": "ea41ec31ab5a8e87aff7f5d434ef59643c049a7b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "config\tinput  lib  working\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "_uuid": "e743a847add2a05dd71a4edd0dd5867fdc97d857"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_dump1\n",
      "load_dump2\n",
      "load_dump3\n",
      "load_dump4\n"
     ]
    }
   ],
   "source": [
    "if isfile(dump_path1):\n",
    "    _, fsubmit1, _, _, _, _ = joblib.load(dump_path1)\n",
    "    print('load_dump1')\n",
    "\n",
    "if isfile(dump_path2):\n",
    "    _, fsubmit2, _, _, _, _ = joblib.load(dump_path2)\n",
    "    print('load_dump2')\n",
    "\n",
    "if isfile(dump_path3):\n",
    "    _, fsubmit3, _, _, _, _ = joblib.load(dump_path3)\n",
    "    print('load_dump3')\n",
    "    \n",
    "if isfile(dump_path4):\n",
    "    _, fsubmit4, _, _, _, _ = joblib.load(dump_path4)\n",
    "    print('load_dump4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "_uuid": "5da694715de38d4ea421b3f109db5c7b74d0af04"
   },
   "outputs": [],
   "source": [
    "fsubmit1 = get_normalized_ndarray(fsubmit1)\n",
    "fsubmit2 = get_normalized_ndarray(fsubmit2)\n",
    "fsubmit3 = get_normalized_ndarray(fsubmit3)\n",
    "fsubmit4 = get_normalized_ndarray(fsubmit4)\n",
    "\n",
    "# fsubmit = (fsubmit1 + fsubmit2 + fsubmit3 + fsubmit4) / 4\n",
    "# fsubmit_pca = pca.fit_transform(fsubmit)\n",
    "# del fsubmit1, fsubmit2, fsubmit3, fsubmit4, fsubmit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "_uuid": "4410c65bb8985740e5d0c6f07be37583945f0a99"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>472</th>\n",
       "      <th>473</th>\n",
       "      <th>474</th>\n",
       "      <th>475</th>\n",
       "      <th>476</th>\n",
       "      <th>477</th>\n",
       "      <th>478</th>\n",
       "      <th>479</th>\n",
       "      <th>480</th>\n",
       "      <th>481</th>\n",
       "      <th>482</th>\n",
       "      <th>483</th>\n",
       "      <th>484</th>\n",
       "      <th>485</th>\n",
       "      <th>486</th>\n",
       "      <th>487</th>\n",
       "      <th>488</th>\n",
       "      <th>489</th>\n",
       "      <th>490</th>\n",
       "      <th>491</th>\n",
       "      <th>492</th>\n",
       "      <th>493</th>\n",
       "      <th>494</th>\n",
       "      <th>495</th>\n",
       "      <th>496</th>\n",
       "      <th>497</th>\n",
       "      <th>498</th>\n",
       "      <th>499</th>\n",
       "      <th>500</th>\n",
       "      <th>501</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.041448</td>\n",
       "      <td>0.039563</td>\n",
       "      <td>0.031313</td>\n",
       "      <td>-0.125862</td>\n",
       "      <td>0.156537</td>\n",
       "      <td>0.069167</td>\n",
       "      <td>0.013188</td>\n",
       "      <td>0.070626</td>\n",
       "      <td>0.141855</td>\n",
       "      <td>0.099244</td>\n",
       "      <td>0.279611</td>\n",
       "      <td>0.366561</td>\n",
       "      <td>-0.030291</td>\n",
       "      <td>0.064520</td>\n",
       "      <td>0.009478</td>\n",
       "      <td>-0.070318</td>\n",
       "      <td>0.018719</td>\n",
       "      <td>0.252980</td>\n",
       "      <td>0.001314</td>\n",
       "      <td>0.013690</td>\n",
       "      <td>0.041215</td>\n",
       "      <td>0.042299</td>\n",
       "      <td>-0.011070</td>\n",
       "      <td>-0.049598</td>\n",
       "      <td>0.182050</td>\n",
       "      <td>-0.132604</td>\n",
       "      <td>-0.039935</td>\n",
       "      <td>-0.018837</td>\n",
       "      <td>-0.011302</td>\n",
       "      <td>-0.019000</td>\n",
       "      <td>-0.040572</td>\n",
       "      <td>-0.064005</td>\n",
       "      <td>0.030874</td>\n",
       "      <td>-0.050336</td>\n",
       "      <td>0.028019</td>\n",
       "      <td>-0.108074</td>\n",
       "      <td>-0.045819</td>\n",
       "      <td>-0.036650</td>\n",
       "      <td>-0.200641</td>\n",
       "      <td>0.045791</td>\n",
       "      <td>...</td>\n",
       "      <td>0.181543</td>\n",
       "      <td>0.200204</td>\n",
       "      <td>0.156890</td>\n",
       "      <td>0.276725</td>\n",
       "      <td>-0.115655</td>\n",
       "      <td>-0.041277</td>\n",
       "      <td>-0.020929</td>\n",
       "      <td>-0.028976</td>\n",
       "      <td>-0.066142</td>\n",
       "      <td>0.308758</td>\n",
       "      <td>0.109737</td>\n",
       "      <td>0.013705</td>\n",
       "      <td>-0.091887</td>\n",
       "      <td>-0.000303</td>\n",
       "      <td>0.040283</td>\n",
       "      <td>0.089873</td>\n",
       "      <td>-0.060350</td>\n",
       "      <td>-0.123852</td>\n",
       "      <td>-0.016194</td>\n",
       "      <td>0.006701</td>\n",
       "      <td>0.095896</td>\n",
       "      <td>0.006138</td>\n",
       "      <td>0.004298</td>\n",
       "      <td>0.218761</td>\n",
       "      <td>-0.108507</td>\n",
       "      <td>-0.038708</td>\n",
       "      <td>-0.146146</td>\n",
       "      <td>0.020920</td>\n",
       "      <td>-0.022856</td>\n",
       "      <td>-0.064708</td>\n",
       "      <td>0.068730</td>\n",
       "      <td>0.029265</td>\n",
       "      <td>0.010050</td>\n",
       "      <td>0.021066</td>\n",
       "      <td>0.179763</td>\n",
       "      <td>-0.047324</td>\n",
       "      <td>0.028580</td>\n",
       "      <td>0.017945</td>\n",
       "      <td>0.017040</td>\n",
       "      <td>-0.001159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.186363</td>\n",
       "      <td>0.005513</td>\n",
       "      <td>0.015065</td>\n",
       "      <td>-0.160529</td>\n",
       "      <td>0.107293</td>\n",
       "      <td>0.087916</td>\n",
       "      <td>0.166024</td>\n",
       "      <td>-0.091205</td>\n",
       "      <td>0.183975</td>\n",
       "      <td>0.091594</td>\n",
       "      <td>-0.037403</td>\n",
       "      <td>0.322657</td>\n",
       "      <td>-0.045940</td>\n",
       "      <td>0.232657</td>\n",
       "      <td>-0.185875</td>\n",
       "      <td>-0.096646</td>\n",
       "      <td>0.010483</td>\n",
       "      <td>0.115613</td>\n",
       "      <td>0.010905</td>\n",
       "      <td>-0.001582</td>\n",
       "      <td>0.141396</td>\n",
       "      <td>0.010848</td>\n",
       "      <td>0.261355</td>\n",
       "      <td>-0.082450</td>\n",
       "      <td>0.258855</td>\n",
       "      <td>-0.108479</td>\n",
       "      <td>-0.010075</td>\n",
       "      <td>0.021705</td>\n",
       "      <td>0.022034</td>\n",
       "      <td>0.018031</td>\n",
       "      <td>-0.048034</td>\n",
       "      <td>-0.117335</td>\n",
       "      <td>0.112809</td>\n",
       "      <td>0.110679</td>\n",
       "      <td>-0.031146</td>\n",
       "      <td>-0.202105</td>\n",
       "      <td>-0.078482</td>\n",
       "      <td>0.017152</td>\n",
       "      <td>-0.090558</td>\n",
       "      <td>-0.048266</td>\n",
       "      <td>...</td>\n",
       "      <td>0.077174</td>\n",
       "      <td>0.099129</td>\n",
       "      <td>0.036000</td>\n",
       "      <td>-0.157822</td>\n",
       "      <td>0.189255</td>\n",
       "      <td>-0.078594</td>\n",
       "      <td>-0.009831</td>\n",
       "      <td>0.125276</td>\n",
       "      <td>-0.028582</td>\n",
       "      <td>-0.063496</td>\n",
       "      <td>0.175293</td>\n",
       "      <td>0.341070</td>\n",
       "      <td>-0.063057</td>\n",
       "      <td>0.161053</td>\n",
       "      <td>-0.186251</td>\n",
       "      <td>0.035643</td>\n",
       "      <td>-0.076369</td>\n",
       "      <td>-0.108206</td>\n",
       "      <td>0.018520</td>\n",
       "      <td>-0.010608</td>\n",
       "      <td>0.046767</td>\n",
       "      <td>0.026661</td>\n",
       "      <td>0.002871</td>\n",
       "      <td>-0.029099</td>\n",
       "      <td>-0.124872</td>\n",
       "      <td>-0.033812</td>\n",
       "      <td>0.043412</td>\n",
       "      <td>-0.159707</td>\n",
       "      <td>0.056864</td>\n",
       "      <td>0.021470</td>\n",
       "      <td>0.076142</td>\n",
       "      <td>-0.071549</td>\n",
       "      <td>0.016120</td>\n",
       "      <td>-0.027957</td>\n",
       "      <td>0.196163</td>\n",
       "      <td>-0.042117</td>\n",
       "      <td>-0.031101</td>\n",
       "      <td>0.036234</td>\n",
       "      <td>-0.015708</td>\n",
       "      <td>-0.031111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.252103</td>\n",
       "      <td>-0.058781</td>\n",
       "      <td>-0.002607</td>\n",
       "      <td>-0.082308</td>\n",
       "      <td>0.028790</td>\n",
       "      <td>0.091574</td>\n",
       "      <td>0.114433</td>\n",
       "      <td>-0.089985</td>\n",
       "      <td>0.106531</td>\n",
       "      <td>0.015792</td>\n",
       "      <td>0.313243</td>\n",
       "      <td>-0.208075</td>\n",
       "      <td>-0.052955</td>\n",
       "      <td>0.358097</td>\n",
       "      <td>-0.206972</td>\n",
       "      <td>-0.059865</td>\n",
       "      <td>0.025922</td>\n",
       "      <td>0.297001</td>\n",
       "      <td>0.014452</td>\n",
       "      <td>0.025113</td>\n",
       "      <td>-0.128335</td>\n",
       "      <td>0.024750</td>\n",
       "      <td>0.105029</td>\n",
       "      <td>-0.046703</td>\n",
       "      <td>-0.035053</td>\n",
       "      <td>-0.091321</td>\n",
       "      <td>0.016225</td>\n",
       "      <td>-0.070021</td>\n",
       "      <td>-0.083525</td>\n",
       "      <td>0.021088</td>\n",
       "      <td>0.009554</td>\n",
       "      <td>-0.080225</td>\n",
       "      <td>-0.009637</td>\n",
       "      <td>0.090299</td>\n",
       "      <td>-0.064082</td>\n",
       "      <td>0.201585</td>\n",
       "      <td>-0.066384</td>\n",
       "      <td>0.053686</td>\n",
       "      <td>-0.010716</td>\n",
       "      <td>-0.042882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.161470</td>\n",
       "      <td>0.108622</td>\n",
       "      <td>0.136361</td>\n",
       "      <td>0.017660</td>\n",
       "      <td>-0.095385</td>\n",
       "      <td>-0.035321</td>\n",
       "      <td>0.018181</td>\n",
       "      <td>0.043948</td>\n",
       "      <td>-0.006928</td>\n",
       "      <td>0.303396</td>\n",
       "      <td>0.042096</td>\n",
       "      <td>-0.039680</td>\n",
       "      <td>0.196750</td>\n",
       "      <td>0.127964</td>\n",
       "      <td>-0.144400</td>\n",
       "      <td>0.094458</td>\n",
       "      <td>-0.078200</td>\n",
       "      <td>-0.123471</td>\n",
       "      <td>0.093241</td>\n",
       "      <td>0.008894</td>\n",
       "      <td>0.097985</td>\n",
       "      <td>-0.025100</td>\n",
       "      <td>0.023103</td>\n",
       "      <td>0.191150</td>\n",
       "      <td>-0.003026</td>\n",
       "      <td>-0.029775</td>\n",
       "      <td>-0.008836</td>\n",
       "      <td>-0.145473</td>\n",
       "      <td>0.191993</td>\n",
       "      <td>0.108420</td>\n",
       "      <td>0.078638</td>\n",
       "      <td>-0.108881</td>\n",
       "      <td>-0.013141</td>\n",
       "      <td>0.088205</td>\n",
       "      <td>0.148569</td>\n",
       "      <td>-0.080073</td>\n",
       "      <td>-0.053219</td>\n",
       "      <td>0.032890</td>\n",
       "      <td>-0.064301</td>\n",
       "      <td>0.014210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.121336</td>\n",
       "      <td>-0.006178</td>\n",
       "      <td>0.038886</td>\n",
       "      <td>-0.114080</td>\n",
       "      <td>0.014270</td>\n",
       "      <td>0.002616</td>\n",
       "      <td>0.098305</td>\n",
       "      <td>0.032510</td>\n",
       "      <td>-0.077315</td>\n",
       "      <td>0.014797</td>\n",
       "      <td>-0.006729</td>\n",
       "      <td>0.097956</td>\n",
       "      <td>-0.006854</td>\n",
       "      <td>-0.012087</td>\n",
       "      <td>-0.053828</td>\n",
       "      <td>-0.021618</td>\n",
       "      <td>-0.033396</td>\n",
       "      <td>-0.063354</td>\n",
       "      <td>-0.076698</td>\n",
       "      <td>0.041540</td>\n",
       "      <td>0.084740</td>\n",
       "      <td>-0.073502</td>\n",
       "      <td>-0.154080</td>\n",
       "      <td>-0.036082</td>\n",
       "      <td>-0.132946</td>\n",
       "      <td>-0.052680</td>\n",
       "      <td>-0.057208</td>\n",
       "      <td>-0.027696</td>\n",
       "      <td>0.087330</td>\n",
       "      <td>-0.016053</td>\n",
       "      <td>-0.068265</td>\n",
       "      <td>-0.096991</td>\n",
       "      <td>-0.041679</td>\n",
       "      <td>-0.034233</td>\n",
       "      <td>-0.085390</td>\n",
       "      <td>0.160511</td>\n",
       "      <td>0.036455</td>\n",
       "      <td>0.027004</td>\n",
       "      <td>-0.066921</td>\n",
       "      <td>-0.074650</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420448</td>\n",
       "      <td>-0.074758</td>\n",
       "      <td>0.060884</td>\n",
       "      <td>-0.026658</td>\n",
       "      <td>-0.000882</td>\n",
       "      <td>-0.086700</td>\n",
       "      <td>0.068755</td>\n",
       "      <td>-0.088188</td>\n",
       "      <td>0.005754</td>\n",
       "      <td>-0.083329</td>\n",
       "      <td>0.077286</td>\n",
       "      <td>0.278744</td>\n",
       "      <td>-0.106108</td>\n",
       "      <td>0.243120</td>\n",
       "      <td>0.097137</td>\n",
       "      <td>0.140377</td>\n",
       "      <td>-0.016914</td>\n",
       "      <td>-0.146498</td>\n",
       "      <td>0.081810</td>\n",
       "      <td>0.028615</td>\n",
       "      <td>0.013707</td>\n",
       "      <td>0.030578</td>\n",
       "      <td>-0.017801</td>\n",
       "      <td>-0.172874</td>\n",
       "      <td>0.274187</td>\n",
       "      <td>0.100285</td>\n",
       "      <td>-0.026547</td>\n",
       "      <td>0.070958</td>\n",
       "      <td>-0.106708</td>\n",
       "      <td>-0.045579</td>\n",
       "      <td>0.061246</td>\n",
       "      <td>-0.056653</td>\n",
       "      <td>0.031352</td>\n",
       "      <td>0.019351</td>\n",
       "      <td>0.037392</td>\n",
       "      <td>-0.078950</td>\n",
       "      <td>0.070972</td>\n",
       "      <td>0.008400</td>\n",
       "      <td>-0.032435</td>\n",
       "      <td>-0.014950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.040922</td>\n",
       "      <td>0.013810</td>\n",
       "      <td>0.029544</td>\n",
       "      <td>-0.147280</td>\n",
       "      <td>-0.101406</td>\n",
       "      <td>0.152857</td>\n",
       "      <td>-0.032904</td>\n",
       "      <td>0.118519</td>\n",
       "      <td>0.061193</td>\n",
       "      <td>-0.011864</td>\n",
       "      <td>-0.113313</td>\n",
       "      <td>-0.214911</td>\n",
       "      <td>-0.038500</td>\n",
       "      <td>0.133813</td>\n",
       "      <td>-0.152216</td>\n",
       "      <td>-0.059635</td>\n",
       "      <td>0.013061</td>\n",
       "      <td>-0.036068</td>\n",
       "      <td>-0.048615</td>\n",
       "      <td>-0.039259</td>\n",
       "      <td>0.008313</td>\n",
       "      <td>0.033965</td>\n",
       "      <td>-0.202626</td>\n",
       "      <td>-0.047108</td>\n",
       "      <td>-0.064787</td>\n",
       "      <td>-0.079189</td>\n",
       "      <td>-0.076913</td>\n",
       "      <td>-0.078856</td>\n",
       "      <td>0.063424</td>\n",
       "      <td>-0.034147</td>\n",
       "      <td>-0.104270</td>\n",
       "      <td>-0.070951</td>\n",
       "      <td>0.016487</td>\n",
       "      <td>-0.083035</td>\n",
       "      <td>-0.023256</td>\n",
       "      <td>0.103354</td>\n",
       "      <td>-0.041095</td>\n",
       "      <td>0.030474</td>\n",
       "      <td>0.137474</td>\n",
       "      <td>-0.159547</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.066096</td>\n",
       "      <td>0.056895</td>\n",
       "      <td>0.020328</td>\n",
       "      <td>-0.211809</td>\n",
       "      <td>-0.058497</td>\n",
       "      <td>-0.157461</td>\n",
       "      <td>0.152163</td>\n",
       "      <td>0.075382</td>\n",
       "      <td>-0.072389</td>\n",
       "      <td>0.054925</td>\n",
       "      <td>0.067439</td>\n",
       "      <td>0.299679</td>\n",
       "      <td>0.243040</td>\n",
       "      <td>-0.002427</td>\n",
       "      <td>-0.014125</td>\n",
       "      <td>0.130144</td>\n",
       "      <td>-0.053600</td>\n",
       "      <td>-0.164761</td>\n",
       "      <td>0.042225</td>\n",
       "      <td>-0.023698</td>\n",
       "      <td>-0.083424</td>\n",
       "      <td>0.012943</td>\n",
       "      <td>-0.099498</td>\n",
       "      <td>0.219841</td>\n",
       "      <td>0.096329</td>\n",
       "      <td>0.059742</td>\n",
       "      <td>0.207715</td>\n",
       "      <td>0.011148</td>\n",
       "      <td>-0.025782</td>\n",
       "      <td>-0.000385</td>\n",
       "      <td>0.064042</td>\n",
       "      <td>-0.144193</td>\n",
       "      <td>0.004440</td>\n",
       "      <td>0.055616</td>\n",
       "      <td>0.025422</td>\n",
       "      <td>-0.100697</td>\n",
       "      <td>-0.070150</td>\n",
       "      <td>0.011717</td>\n",
       "      <td>-0.021411</td>\n",
       "      <td>-0.007094</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2      ...          509       510       511\n",
       "0 -0.041448  0.039563  0.031313    ...     0.017945  0.017040 -0.001159\n",
       "1 -0.186363  0.005513  0.015065    ...     0.036234 -0.015708 -0.031111\n",
       "2  0.252103 -0.058781 -0.002607    ...     0.032890 -0.064301  0.014210\n",
       "3 -0.121336 -0.006178  0.038886    ...     0.008400 -0.032435 -0.014950\n",
       "4  0.040922  0.013810  0.029544    ...     0.011717 -0.021411 -0.007094\n",
       "\n",
       "[5 rows x 512 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(fsubmit1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "_uuid": "fe1f7f29b830215b4e1460826cebaaba1ee0badf"
   },
   "outputs": [],
   "source": [
    "def get_pred(fsubmit):\n",
    "    fsubmit_pca = pca.fit_transform(fsubmit)\n",
    "    y_pred = gbm.predict(fsubmit_pca, num_iteration=gbm.best_iteration)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "_uuid": "ec036e7304b45deef2139a789246b7135a4cede0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp_pred : [[0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]\n",
      " ...\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]]\n",
      "y_pred : [[0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]\n",
      " ...\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 25%|██▌       | 1/4 [00:19<00:58, 19.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp_pred : [[0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.00019979 0.0001887 ]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]\n",
      " ...\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.00019979 0.00018869]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.00019979 0.0001887 ]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]]\n",
      "y_pred : [[0.00041127 0.00042179 0.00043289 ... 0.00042179 0.00039959 0.00037739]\n",
      " [0.00041127 0.00042179 0.00043289 ... 0.00042179 0.00039959 0.00037739]\n",
      " [0.00041127 0.00042179 0.00043289 ... 0.00042179 0.00039959 0.00037739]\n",
      " ...\n",
      " [0.00041127 0.00042179 0.00043289 ... 0.00042179 0.00039959 0.00037739]\n",
      " [0.00041127 0.00042179 0.00043289 ... 0.00042179 0.00039959 0.00037739]\n",
      " [0.00041127 0.00042179 0.00043289 ... 0.00042179 0.00039959 0.00037739]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 50%|█████     | 2/4 [00:38<00:38, 19.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp_pred : [[0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.00019979 0.0001887 ]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.00019979 0.0001887 ]\n",
      " ...\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.00019979 0.00018869]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]]\n",
      "y_pred : [[0.00061691 0.00063268 0.00064933 ... 0.00063268 0.00059939 0.00056609]\n",
      " [0.00061691 0.00063268 0.00064933 ... 0.00063268 0.00059938 0.00056609]\n",
      " [0.00061691 0.00063268 0.00064933 ... 0.00063268 0.00059938 0.00056609]\n",
      " ...\n",
      " [0.00061691 0.00063268 0.00064933 ... 0.00063268 0.00059938 0.00056609]\n",
      " [0.00061691 0.00063268 0.00064933 ... 0.00063268 0.00059939 0.00056609]\n",
      " [0.00061691 0.00063268 0.00064933 ... 0.00063268 0.00059939 0.00056609]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      " 75%|███████▌  | 3/4 [00:58<00:19, 19.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp_pred : [[0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]\n",
      " ...\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.00019979 0.0001887 ]\n",
      " [0.00020564 0.00021089 0.00021644 ... 0.00021089 0.0001998  0.0001887 ]]\n",
      "y_pred : [[0.00082254 0.00084358 0.00086578 ... 0.00084358 0.00079918 0.00075478]\n",
      " [0.00082254 0.00084358 0.00086578 ... 0.00084358 0.00079918 0.00075478]\n",
      " [0.00082254 0.00084358 0.00086578 ... 0.00084358 0.00079918 0.00075478]\n",
      " ...\n",
      " [0.00082254 0.00084358 0.00086578 ... 0.00084358 0.00079918 0.00075478]\n",
      " [0.00082254 0.00084358 0.00086578 ... 0.00084358 0.00079918 0.00075478]\n",
      " [0.00082254 0.00084358 0.00086578 ... 0.00084358 0.00079918 0.00075478]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [01:17<00:00, 19.32s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['gbm_joblib_with_pred']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fsubmit_list = [fsubmit1, fsubmit2, fsubmit3, fsubmit4]\n",
    "fsubmit_list_len = len(fsubmit_list)\n",
    "y_pred = 0\n",
    "for fsubmit in tqdm(fsubmit_list):\n",
    "    tmp_pred = get_pred(fsubmit)\n",
    "    print('tmp_pred : ' + str(tmp_pred))\n",
    "    y_pred = y_pred + tmp_pred\n",
    "    print('y_pred : ' + str(y_pred))\n",
    "    del fsubmit\n",
    "y_pred = y_pred / fsubmit_list_len\n",
    "\n",
    "dump_data = (gbm, params, y_pred)\n",
    "joblib.dump(dump_data, 'gbm_joblib_with_pred', compress=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "_uuid": "fdcf618fbb4116f4b29ae1f2621d852b3a14eb19"
   },
   "outputs": [],
   "source": [
    "# # y_pred = gbm.predict(fsubmit_pca, num_iteration=gbm.best_iteration)\n",
    "# # del fsubmit_pca\n",
    "# K = 5\n",
    "\n",
    "# # ソートはされていない上位k件のインデックス\n",
    "# unsorted_max_indices = np.argpartition(-y_pred, K)[:K]\n",
    "# # 上位k件の値\n",
    "# y = y_pred[unsorted_max_indices]\n",
    "\n",
    "# # 大きい順にソートし、インデックスを取得\n",
    "# indices = np.argsort(-y)\n",
    "\n",
    "# # 類似度上位k件のインデックス\n",
    "# max_k_indices = unsorted_max_indices[indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "_uuid": "1dbd6389b7cc3d2eee468863a46bb7356b55a160"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7960, 5005)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "_uuid": "26aed59ac22a429f273b5deebe04e8aa252bd797"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0002520181232695243"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "_uuid": "f669abfc361825d04e0d1f19565d75a715c7f539",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "      <th>30</th>\n",
       "      <th>31</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>...</th>\n",
       "      <th>4965</th>\n",
       "      <th>4966</th>\n",
       "      <th>4967</th>\n",
       "      <th>4968</th>\n",
       "      <th>4969</th>\n",
       "      <th>4970</th>\n",
       "      <th>4971</th>\n",
       "      <th>4972</th>\n",
       "      <th>4973</th>\n",
       "      <th>4974</th>\n",
       "      <th>4975</th>\n",
       "      <th>4976</th>\n",
       "      <th>4977</th>\n",
       "      <th>4978</th>\n",
       "      <th>4979</th>\n",
       "      <th>4980</th>\n",
       "      <th>4981</th>\n",
       "      <th>4982</th>\n",
       "      <th>4983</th>\n",
       "      <th>4984</th>\n",
       "      <th>4985</th>\n",
       "      <th>4986</th>\n",
       "      <th>4987</th>\n",
       "      <th>4988</th>\n",
       "      <th>4989</th>\n",
       "      <th>4990</th>\n",
       "      <th>4991</th>\n",
       "      <th>4992</th>\n",
       "      <th>4993</th>\n",
       "      <th>4994</th>\n",
       "      <th>4995</th>\n",
       "      <th>4996</th>\n",
       "      <th>4997</th>\n",
       "      <th>4998</th>\n",
       "      <th>4999</th>\n",
       "      <th>5000</th>\n",
       "      <th>5001</th>\n",
       "      <th>5002</th>\n",
       "      <th>5003</th>\n",
       "      <th>5004</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000205</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000183</td>\n",
       "      <td>0.000194</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.000189</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1         2       ...         5002    5003      5004\n",
       "0   0.000206  0.000211  0.000216    ...     0.000211  0.0002  0.000189\n",
       "1   0.000206  0.000211  0.000216    ...     0.000211  0.0002  0.000189\n",
       "2   0.000206  0.000211  0.000216    ...     0.000211  0.0002  0.000189\n",
       "3   0.000206  0.000211  0.000216    ...     0.000211  0.0002  0.000189\n",
       "4   0.000206  0.000211  0.000216    ...     0.000211  0.0002  0.000189\n",
       "5   0.000206  0.000211  0.000216    ...     0.000211  0.0002  0.000189\n",
       "6   0.000206  0.000211  0.000216    ...     0.000211  0.0002  0.000189\n",
       "7   0.000206  0.000211  0.000216    ...     0.000211  0.0002  0.000189\n",
       "8   0.000206  0.000211  0.000216    ...     0.000211  0.0002  0.000189\n",
       "9   0.000206  0.000211  0.000216    ...     0.000211  0.0002  0.000189\n",
       "10  0.000206  0.000211  0.000216    ...     0.000211  0.0002  0.000189\n",
       "11  0.000206  0.000211  0.000216    ...     0.000211  0.0002  0.000189\n",
       "12  0.000206  0.000211  0.000216    ...     0.000211  0.0002  0.000189\n",
       "13  0.000206  0.000211  0.000216    ...     0.000211  0.0002  0.000189\n",
       "14  0.000206  0.000211  0.000216    ...     0.000211  0.0002  0.000189\n",
       "\n",
       "[15 rows x 5005 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_df = pd.DataFrame(y_pred)\n",
    "pred_df.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "d9fa4ae676bf22140b858fe8271f4a07dfa4d37a"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
